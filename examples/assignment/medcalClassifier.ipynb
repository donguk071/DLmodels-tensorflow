{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c:\\\\Users\\\\drago\\\\university\\\\23.1 semester\\\\DL\\\\DLmodels-tensorflow\\\\examples\\\\assignment', 'c:\\\\Users\\\\drago\\\\anaconda3\\\\envs\\\\py36tf131\\\\python36.zip', 'c:\\\\Users\\\\drago\\\\anaconda3\\\\envs\\\\py36tf131\\\\DLLs', 'c:\\\\Users\\\\drago\\\\anaconda3\\\\envs\\\\py36tf131\\\\lib', 'c:\\\\Users\\\\drago\\\\anaconda3\\\\envs\\\\py36tf131', '', 'c:\\\\Users\\\\drago\\\\anaconda3\\\\envs\\\\py36tf131\\\\lib\\\\site-packages', 'c:\\\\Users\\\\drago\\\\anaconda3\\\\envs\\\\py36tf131\\\\lib\\\\site-packages\\\\win32', 'c:\\\\Users\\\\drago\\\\anaconda3\\\\envs\\\\py36tf131\\\\lib\\\\site-packages\\\\win32\\\\lib', 'c:\\\\Users\\\\drago\\\\anaconda3\\\\envs\\\\py36tf131\\\\lib\\\\site-packages\\\\Pythonwin', 'c:\\\\Users\\\\drago\\\\anaconda3\\\\envs\\\\py36tf131\\\\lib\\\\site-packages\\\\IPython\\\\extensions', 'C:\\\\Users\\\\drago\\\\.ipython', 'C:\\\\Users\\\\drago\\\\university\\\\23.1 semester\\\\DL\\\\DLmodels-tensorflow', 'C:\\\\Users\\\\drago\\\\university\\\\23.1 semester\\\\DL\\\\DLmodels-tensorflow']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(\n",
    "    'C:\\\\Users\\\\drago\\\\university\\\\23.1 semester\\\\DL\\\\DLmodels-tensorflow')\n",
    "print(sys.path)\n",
    "\n",
    "from tensorflow import keras\n",
    "from  tensorflow.keras.optimizers import Adam \n",
    "from readData import my_data_reader\n",
    "from keras import models, layers\n",
    "from keras import Input\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers, initializers, regularizers, metrics\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.layers import BatchNormalization, Conv2D, Activation, Dense, GlobalAveragePooling2D, MaxPooling2D, ZeroPadding2D, Add\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import glob\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read folder path : ['../../data/medical/train\\\\ad', '../../data/medical/train\\\\normal']\n",
      "Read folder path : ['../../data/medical/test\\\\ad', '../../data/medical/test\\\\normal']\n",
      "size of data set : 280\n",
      "size of each label : [80, 80, 60, 60]\n",
      "img resize 150 to 150\n",
      "labeling data set : 0/280\n",
      "labeling data set : 100/280\n",
      "labeling data set : 200/280\n",
      "labeling data done : 280/280\n"
     ]
    }
   ],
   "source": [
    "x_train = []\n",
    "x_test = []\n",
    "y_train = []\n",
    "y_test = []\n",
    "\n",
    "\n",
    "img_size = 150\n",
    "\n",
    "train_folder_path = glob.glob(\"../../data/medical/train/*\")\n",
    "print(\"Read folder path : \" + str(train_folder_path))\n",
    "test_folder_path = glob.glob(\"../../data/medical/test/*\")\n",
    "print(\"Read folder path : \" + str(test_folder_path))\n",
    "\n",
    "\n",
    "folder_path = train_folder_path + test_folder_path\n",
    "\n",
    "numFiles = [0] * len(folder_path)  # numFiles 리스트 초기화\n",
    "file_path = []\n",
    "for i, path in enumerate(folder_path):\n",
    "        temp_path = glob.glob(path + \"/*\")  # 폴더 내 모든 파일 경로 가져오기\n",
    "        numFiles[i] = len(temp_path)\n",
    "        file_path += temp_path\n",
    "\n",
    "print(\"size of data set : \" + str(len(file_path)))\n",
    "print(\"size of each label : \" + str(numFiles))\n",
    "\n",
    "data = []\n",
    "for i, path in enumerate(file_path):\n",
    "    img = Image.open(path)\n",
    "    if i == 0 : print(\"img resize \" + str(img.size[1]) + \" to \" + str(img_size))\n",
    "    img = img.resize((img_size, img_size))\n",
    "    img = np.asarray(img)\n",
    "    # print(img.shape)\n",
    "\n",
    "    if i <= 80:  # 파일이 속한 폴더의 인덱스 계산\n",
    "        img_label = 0            \n",
    "        \n",
    "    elif i <= 160 and i > 80:  # 파일이 속한 폴더의 인덱스 계산\n",
    "        img_label = 1            \n",
    "        \n",
    "    elif i <= 220 and i > 160:  # 파일이 속한 폴더의 인덱스 계산\n",
    "        img_label = 0            \n",
    "        \n",
    "    elif i <= 280 and i > 220:  # 파일이 속한 폴더의 인덱스 계산\n",
    "        img_label = 1            \n",
    "        \n",
    "    else :\n",
    "        img_label = 0      \n",
    "        \n",
    "    if i % 100 == 0:\n",
    "        print(\"labeling data set : \" + str(i) + \"/\" + str(len(file_path)))\n",
    "    data.append((img, img_label))\n",
    "    # break\n",
    "print(\"labeling data done : \" + str(len(file_path)) + \"/\" + str(len(file_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\drago\\anaconda3\\envs\\py36tf131\\lib\\site-packages\\ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.array(data)\n",
    "a = [row[1] for row in data]\n",
    "np.unique(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([[[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]]], dtype=uint8),\n",
       "       0], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 2)\n",
      "(150, 150, 3)\n",
      "(120, 2)\n",
      "(150, 150, 3)\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data= np.split(data, [160])\n",
    "print(train_data.shape)\n",
    "print(train_data[0][0].shape)\n",
    "print(test_data.shape)\n",
    "print(test_data[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 2)\n",
      "(150, 150, 3)\n",
      "(320, 2)\n",
      "(150, 150, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\drago\\anaconda3\\envs\\py36tf131\\lib\\site-packages\\ipykernel_launcher.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "\n",
    "augmentedset = []\n",
    "for i in range(160):\n",
    "    x = np.array(train_data[i][0])\n",
    "    y = train_data[i][1]\n",
    "    newdata = np.fliplr(x)\n",
    "    augmentedset.append((newdata, y))\n",
    "\n",
    "\n",
    "augmentedset = np.array(augmentedset)\n",
    "print(augmentedset.shape)\n",
    "print(augmentedset[0][0].shape)\n",
    "train_data  = np.concatenate((train_data, augmentedset), axis=0)\n",
    "print(train_data.shape)\n",
    "print(train_data[0][0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 150, 3)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target = [row[1] for row in train_data]\n",
    "train_data2 = [row[0] for row in train_data]\n",
    "\n",
    "test_target = [row[1] for row in test_data]\n",
    "test_data2 = [row[0] for row in test_data]\n",
    "\n",
    "train_data2[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(train_target))\n",
    "print(np.unique(test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(train_data2) / 255.0\n",
    "x_test = np.array(test_data2) / 255.0\n",
    "\n",
    "y_train = np.array(train_target) / 1.0\n",
    "y_test = np.array(test_target) / 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1.]\n",
      "[0. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(y_test))\n",
    "print(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((320, 150, 150, 3), (120, 150, 150, 3), (120,), (320,))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape , x_test.shape , y_test.shape , y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from  tensorflow.keras.optimizers import Adam \n",
    "\n",
    "model = keras.Sequential([\n",
    "    # 이걸 수정해보자\n",
    "    keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation ='ReLU' ),\n",
    "    keras.layers.MaxPooling2D((2,2)),\n",
    "    keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation ='ReLU' ),\n",
    "    keras.layers.MaxPooling2D((2,2)),\n",
    "    keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation ='ReLU' ),\n",
    "    keras.layers.MaxPooling2D((2,2)),\n",
    "    keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation ='ReLU' ),\n",
    "    keras.layers.MaxPooling2D((2,2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(2000, activation = 'ReLU'),\n",
    "    #classifing 2\n",
    "    keras.layers.Dense(2, activation = 'softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model definded\n",
      "\n",
      " <bound method Model.summary of <keras.engine.sequential.Sequential object at 0x000001AD8723FD68>>\n",
      "\n",
      "\n",
      "************ TRAINING START ************ \n",
      "float64\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 7s 661ms/step - loss: 0.4954 - accuracy: 0.7594 - val_loss: 0.4719 - val_accuracy: 0.7750\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 7s 682ms/step - loss: 0.2332 - accuracy: 0.9250 - val_loss: 0.2042 - val_accuracy: 0.9500\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 6s 617ms/step - loss: 0.1703 - accuracy: 0.9438 - val_loss: 0.2066 - val_accuracy: 0.9500\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 7s 714ms/step - loss: 0.1857 - accuracy: 0.9281 - val_loss: 0.2688 - val_accuracy: 0.9083\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 8s 811ms/step - loss: 0.1114 - accuracy: 0.9594 - val_loss: 0.1865 - val_accuracy: 0.9500\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 8s 790ms/step - loss: 0.1041 - accuracy: 0.9625 - val_loss: 0.1645 - val_accuracy: 0.9583\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 8s 782ms/step - loss: 0.0820 - accuracy: 0.9812 - val_loss: 0.3550 - val_accuracy: 0.9000\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 7s 738ms/step - loss: 0.0740 - accuracy: 0.9781 - val_loss: 0.1961 - val_accuracy: 0.9583\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 6s 626ms/step - loss: 0.0631 - accuracy: 0.9812 - val_loss: 0.2926 - val_accuracy: 0.9250\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 6s 618ms/step - loss: 0.0597 - accuracy: 0.9844 - val_loss: 0.1779 - val_accuracy: 0.9583\n",
      "acc is :  95.83333134651184\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer = Adam(learning_rate= 0.001), metrics=['accuracy'],loss = 'sparse_categorical_crossentropy')\n",
    "print(\"model definded\\n\\n\", model.summary)\n",
    "\n",
    "print(\"\\n\\n************ TRAINING START ************ \")\n",
    "print(y_train.dtype)\n",
    "history = model.fit(x_train, y_train, epochs=10,\n",
    "                    validation_data=(x_test, y_test))\n",
    "\n",
    "res = model.evaluate(x_test,y_test,verbose = 0 )\n",
    "print(\"acc is : \", res[1]* 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36tf131",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
